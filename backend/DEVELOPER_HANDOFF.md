# Coventry University Student Assistant - Developer Handoff

**Project:** Coventry University Student Assistant (AI Chatbot Backend)  
**Created:** 2025  
**Status:** âœ… READY FOR TESTING  
**Tech Stack:** Node.js + Express + TypeScript + Ollama (FREE LLM)

---

## ğŸ“‹ Executive Summary

This is an AI-powered backend that helps Coventry University students with administrative queries using RAG (Retrieval-Augmented Generation).

**What's Been Completed:**
1. âœ… **Data Extraction** - 90 documents from Coventry University website
2. âœ… **Backend Structure** - Express.js with TypeScript
3. âœ… **FREE LLM Integration** - Ollama (no API costs!)
4. âœ… **Knowledge Base Ingestion** - All documents embedded and cached

**Key Feature:** Uses Ollama for completely FREE local LLM inference - no API costs!

---

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+
- Ollama installed (`winget install Ollama.Ollama`)
- Ollama models pulled:
  ```bash
  ollama pull llama3.2
  ollama pull nomic-embed-text
  ```

### Start the Server
```bash
cd backend
npm install        # First time only
npm run ingest     # First time only (generates embeddings)
npm run dev        # Start development server
```

### Test Endpoints
```bash
# Health check
curl http://localhost:3000/api/health

# Search
curl -X POST http://localhost:3000/api/search \
  -H "Content-Type: application/json" \
  -d '{"query": "accommodation fees"}'

# Chat
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "What support services are available?"}'
```

---

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ knowledge_base/           # 10 JSON files with 90 documents
â”‚   â””â”€â”€ embeddings_cache.json     # Pre-computed embeddings
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ env.ts                # Environment configuration
â”‚   â”‚   â”œâ”€â”€ ollama.ts             # FREE local LLM client
â”‚   â”‚   â”œâ”€â”€ openai.ts             # Optional paid alternative
â”‚   â”‚   â””â”€â”€ supabase.ts           # Optional database
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ chatService.ts        # RAG-powered chat
â”‚   â”‚   â”œâ”€â”€ embeddingService.ts   # Vector embeddings
â”‚   â”‚   â””â”€â”€ knowledgeService.ts   # Knowledge base management
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ chat.ts               # POST /api/chat
â”‚   â”‚   â”œâ”€â”€ search.ts             # POST /api/search
â”‚   â”‚   â””â”€â”€ health.ts             # GET /api/health
â”‚   â””â”€â”€ index.ts                  # Express server
â”œâ”€â”€ .env                          # Configuration (Ollama mode)
â”œâ”€â”€ package.json
â”œâ”€â”€ test_api.py                   # Python test script
â””â”€â”€ README.md
```

---

## ğŸ”§ Configuration

### Current Setup (FREE - Ollama)
```env
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
```

### Alternative (Paid - OpenAI)
```env
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-your-key-here
```

---

## ğŸ“š Knowledge Base Coverage

| Category | Documents | Topics |
|----------|-----------|--------|
| Student Support | 4 | Success coaches, Phoenix+ |
| Academic Support | 6 | Tutors, library, CAW, sigma |
| Health & Wellbeing | 12 | Mental health, disability, medical |
| Fees & Finance | 11 | Tuition, scholarships, cost of living |
| International Students | 14 | Visas, English requirements |
| Accommodation | 9 | Halls, fees, applications |
| Employability | 5 | Careers, placements, global opportunities |
| Applications | 7 | Admissions process |
| Campus Locations | 12 | All campuses and locations |
| General Info | 10 | Contacts, portals, FAQs |

**Total: 90 documents**

---

## ğŸ”Œ API Reference

### GET /api/health
Returns system health and LLM status.

**Response:**
```json
{
  "status": "healthy",
  "provider": "ollama",
  "documentsLoaded": 90,
  "timestamp": "2025-01-15T12:00:00Z"
}
```

### POST /api/search
Semantic search across the knowledge base.

**Request:**
```json
{
  "query": "How much does accommodation cost?",
  "limit": 5
}
```

**Response:**
```json
{
  "success": true,
  "results": [
    {
      "document": {
        "id": "...",
        "title": "Accommodation Fees",
        "content": "...",
        "url": "https://..."
      },
      "score": 0.8542,
      "category": "Accommodation"
    }
  ]
}
```

### POST /api/chat
Chat with the AI assistant (uses RAG).

**Request:**
```json
{
  "message": "What support services are available for students?",
  "conversationId": "optional-uuid"
}
```

**Response:**
```json
{
  "success": true,
  "response": "Coventry University offers various support services...",
  "conversationId": "uuid",
  "sources": [
    { "title": "Student Support Overview", "url": "...", "category": "Student Support" }
  ]
}
```

---

## âš¡ Performance Notes

- **Response Time:** 10-30 seconds on CPU, 2-5 seconds with GPU
- **Memory:** llama3.2 uses ~2-4GB RAM when loaded
- **Embedding Cache:** Pre-computed for instant search

---

## ğŸ¯ Next Steps

1. **Build Frontend** - React/Vue chat interface
2. **Improve Responses** - Add more documents or use larger model
3. **Deploy** - Set up production server with GPU for speed
4. **Optional Supabase** - Enable for user accounts and history

---

## ğŸ› Troubleshooting

**Server won't start:**
- Check if Ollama is running: `ollama list`
- Check port 3000 is free

**Slow responses:**
- Normal on CPU - consider GPU
- Use smaller model: `OLLAMA_MODEL=llama3.2:1b`

**Search returns no results:**
- Run `npm run ingest` to regenerate embeddings

---

## ğŸ“ Data Sources

All data extracted from: https://wayfinder.coventry.ac.uk/s/guide
